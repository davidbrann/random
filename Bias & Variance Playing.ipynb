{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4cccf16a",
   "metadata": {},
   "source": [
    "# Bias & Variance playing around \n",
    "\n",
    "from \n",
    "https://www.bmc.com/blogs/bias-variance-machine-learning/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9d0fdc27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BASIC DECISION TREE EXAMPLE \n",
    "\n",
    "from mlxtend.evaluate import bias_variance_decomp\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from mlxtend.data import iris_data\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9971aff3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Expected Loss: 0.0607n\n",
      "Average Bias: 0.0222\n",
      "Average Variance: 0.0393\n"
     ]
    }
   ],
   "source": [
    "# Get Data Set\n",
    "X, y = iris_data()\n",
    "\n",
    "X_train_ds, X_test_ds, y_train_ds, y_test_ds = train_test_split(X, y, test_size=0.3, random_state=123, \n",
    "                                                                shuffle=True, stratify=y)\n",
    "\n",
    "# Define Algorithm \n",
    "tree = DecisionTreeClassifier(random_state=123)\n",
    "\n",
    "# Get Bias and Variance - bias_variance_decomp function\n",
    "avg_expected_loss, avg_bias, avg_var = bias_variance_decomp(tree, X_train_ds, y_train_ds, X_test_ds, y_test_ds, \n",
    "                                                            loss='0-1_loss', random_seed=123, num_rounds=1000)\n",
    "\n",
    "# Display Bias and Variance\n",
    "print(f'Average Expected Loss: {round(avg_expected_loss, 4)}')\n",
    "print(f'Average Bias: {round(avg_bias, 4)}')\n",
    "print(f'Average Variance: {round(avg_var, 4)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "df11c4da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Expected Loss: 0.0459n\n",
      "Average Bias: 0.0222\n",
      "Average Variance: 0.024\n"
     ]
    }
   ],
   "source": [
    "#  BAGGING EXAMPLE \n",
    "\n",
    "from mlxtend.evaluate import bias_variance_decomp\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from mlxtend.data import iris_data\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "# Get Data Set\n",
    "X, y = iris_data()\n",
    "X_train_ds, X_test_ds, y_train_ds, y_test_ds = train_test_split(X, y,\n",
    "test_size=0.3,\n",
    "random_state=123,\n",
    "shuffle=True,\n",
    "stratify=y)\n",
    "# Define Algorithm \n",
    "tree = DecisionTreeClassifier(random_state=123)\n",
    "bag = BaggingClassifier(base_estimator=tree,\n",
    "n_estimators=100,\n",
    "random_state=123)\n",
    "# Get Bias and Variance - bias_variance_decomp function\n",
    "avg_expected_loss, avg_bias, avg_var = bias_variance_decomp(\n",
    "bag, X_train_ds, y_train_ds, X_test_ds, y_test_ds, \n",
    "loss='0-1_loss',\n",
    "random_seed=123,\n",
    "num_rounds=1000)\n",
    "# Display Bias and Variance\n",
    "print(f'Average Expected Loss: {round(avg_expected_loss, 4)}n')\n",
    "print(f'Average Bias: {round(avg_bias, 4)}')\n",
    "print(f'Average Variance: {round(avg_var, 4)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f9218c05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lead Square\n",
      "nLeast Square Coefficients: [[2.]]\n",
      "Actual= [8.8]  Preds= [8.]\n",
      "Variance 0.0\n",
      "Bias: 13.88\n",
      "Actual= [14.]  Preds= [10.]\n",
      "Variance 58.98\n",
      "Bias: 13.88\n",
      "Actual= [17.]  Preds= [12.]\n",
      "Variance 101.15\n",
      "Bias: 13.88\n",
      "Ridge \n",
      "nRidged Coefficients: [[1.9047619]]\n",
      "Actual= [8.8]  Preds= [7.80952381]\n",
      "Variance 0.0\n",
      "Bias: 16.1\n",
      "Actual= [14.]  Preds= [9.71428571]\n",
      "Variance 75.57\n",
      "Bias: 16.1\n",
      "Actual= [17.]  Preds= [11.61904762]\n",
      "Variance 132.99\n",
      "Bias: 16.1\n",
      "Lasso\n",
      "nLasso Coefficients: [1.85]\n",
      "Actual= [8.8]  Preds= 7.7\n",
      "Variance 0.0\n",
      "Bias: 17.46\n",
      "Actual= [14.]  Preds= 9.55\n",
      "Variance 86.42\n",
      "Bias: 17.46\n",
      "Actual= [17.]  Preds= 11.400000000000002\n",
      "Variance 154.25\n",
      "Bias: 17.46\n"
     ]
    }
   ],
   "source": [
    "# LINEAR REGRESSION - LEAST-SQUARSE,RIDGE, AND LASSO \n",
    "\n",
    "from sklearn import linear_model\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "def calculate_bias_variance(xTest, ytest, model):\n",
    "    ar = np.array([[[1],[2],[3]], [[2],[4],[6]]])\n",
    "    y = ar[1,:]\n",
    "    x = ar[0,:]\n",
    "\n",
    "    if model == 1:\n",
    "        reg = linear_model.LinearRegression()\n",
    "        reg.fit(x,y)\n",
    "        print(f'nLeast Square Coefficients: {reg.coef_}')\n",
    "    if model == 2:\n",
    "        reg = linear_model.Ridge (alpha = 0.1)\n",
    "        reg.fit(x,y)\n",
    "        print(f'nRidged Coefficients: {reg.coef_}')\n",
    "    if model == 3:    \n",
    "        reg = linear_model.Lasso(alpha = 0.1)\n",
    "        reg.fit(x,y)\n",
    "        print(f'nLasso Coefficients: {reg.coef_}')\n",
    "        \n",
    "    preds = reg.predict(xTest)\n",
    "    er = []\n",
    "\n",
    "    for i in range(len(ytest)):\n",
    "        print( \"Actual=\", ytest[i], \" Preds=\", preds[i])\n",
    "        x = (ytest[i] - preds[i]) **2\n",
    "        er.append(x)\n",
    "        variance_value = np.var(er)\n",
    "        print (f\"Variance {round(variance_value, 2)}\")\n",
    "        print(f\"Bias: {round(mean_squared_error(ytest,preds), 2)}\")\n",
    "\n",
    "                    \n",
    "dateset_a = np.array([[4],[5],[6]])\n",
    "dateset_b = np.array([[8.8],[14],[17]])\n",
    "\n",
    "# Least Square Coefficients\n",
    "print('Lead Square')\n",
    "calculate_bias_variance(dateset_a,dateset_b, 1)\n",
    "\n",
    "# Ridged Coefficients\n",
    "print('Ridge ')\n",
    "calculate_bias_variance(dateset_a,dateset_b, 2)\n",
    "\n",
    "# Lasso Coefficients\n",
    "print('Lasso')\n",
    "calculate_bias_variance(dateset_a,dateset_b, 3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
